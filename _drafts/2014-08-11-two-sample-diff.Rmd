---
layout: post
title: "Apples and pears - differences between two groups"
description: ""
category: r
tags: [AB testing, t-test, inferential statistics]
---

One of the most common problems in inferential statistics involves determining whether there is a difference between two groups. The height of men and women, effects of two experimental drugs, average internet usage in two geographical areas. In the industry, people often refer to it as A/B testing. It sounds simple enough, you have two samples $X_1, X_2,\ldots,X_{n1}$ and $Y_1, Y_2,\ldots,Y_{n2}$, say that each $X_i$ represents the amount of apples on a particular tree in your garden and $Y_i$ represents the number of pears. If you are interested in the average difference between the number of apples and pears on a tree, you can calculate the mean $\hat{x}=\frac{1}{n}\sum_i x_i$ of each group and compare them.

The crux of the problem lies in the fact that the means of the two groups $\hat{x}$ and $\hat{y}$ are calculated using sample data, and as such, they are only estimates of the true population means $\mu_x$ and $\mu_y$ (think of the true population as all apple and pear trees in the world). Repeating the exercise in your neihbours garden would lead to different estimates of $\hat{x} - \hat{y}$, which is why statistics is required to make a statement about the "true" difference $\mu_x - \mu_y$ (between the two populations).

In practice there are many questions. What to do if the sample data is not normally distributed? Should we only care about the differences in the mean, or consider variance as well? There are statistical tests for almost everything, normality, equality of variance (homoskedasticity), but isn't that multiple testing? And what about statistical power?

Let's see whether we can break this down. Can we assume the sample data has Normal distribution? 

Two sample t-test.
The classic two-sample t-test assumes that the data is an i.i.d. sample from an approximately normal distribution with equal variance: $X_i \sim \mathcal{N}(\mu_x, \sigma^2)$ and $Y_i \sim \mathcal{N}(\mu_y, \sigma^2)$. The Welch test softens the requirement of equal variance between the groups by allowing a distinct $\sigma^2_x$ for apples and $\sigma^2_y$ for pears. However, both these tests are only useful if the underlying distribution is approximately normal.

If the data is non-normal, can we assume that the two samples have the same distribution form?
If the exact distribution is unknown, the non-parametric Mann???Whitney U test (also known as Wilcoxon rank-sum test). It makes no assumptions about the form of the distribution, but requires



